#!/bin/bash
set -e

echo "ğŸš€ Starting Daily ArXiv Update Workflow..."

# --- 1. å®šä¹‰æ—¥æœŸå’Œæ–‡ä»¶å ---
# ä½¿ç”¨åŒ—äº¬æ—¶åŒºï¼Œç¡®ä¿æ–‡ä»¶åä¸æˆ‘ä»¬çš„æ„ŸçŸ¥ä¸€è‡´
today=$(TZ=Asia/Shanghai date "+%Y-%m-%d")
yesterday=$(TZ=Asia/Shanghai date -d "1 day ago" "+%Y-%m-%d")
day_before_yesterday=$(TZ=Asia/Shanghai date -d "2 days ago" "+%Y-%m-%d")
echo "âœ… Workflow date set to: ${today} (Asia/Shanghai)"

# å®šä¹‰æ‰€æœ‰ä¸­é—´æ–‡ä»¶å’Œæœ€ç»ˆæ–‡ä»¶çš„è·¯å¾„
RAW_JSONL_FILE="data/${today}.jsonl"
UNIQUE_JSONL_FILE="data/${today}_unique.jsonl"
NEW_ONLY_JSONL_FILE="data/${today}_new_only.jsonl" # **åªåŒ…å«çº¯æ–°è®ºæ–‡çš„æ–‡ä»¶**
ENHANCED_JSONL_FILE="data/${today}_new_only_AI_enhanced_Chinese.jsonl" # AI å¢å¼ºæ–‡ä»¶åä¹Ÿåº”åŸºäºæ–°æ–‡ä»¶
FINAL_MD_FILE="data/${today}.md"

# å®šä¹‰ç”¨äºæ¯”è¾ƒçš„å†å²æ–‡ä»¶åˆ—è¡¨
PREVIOUS_DAY_FILES=("data/${yesterday}_unique.jsonl" "data/${day_before_yesterday}_unique.jsonl")

# --- 2. çˆ¬å–å’Œå»é‡ ---
echo "--- Step 1: Crawling and Deduplicating Today's Data ---"
# ç¡®ä¿è°ƒç”¨çš„æ˜¯æ‚¨æ­£ç¡®çš„ Scrapy é¡¹ç›®å’Œçˆ¬è™«
(cd daily_arxiv && scrapy crawl arxiv -o ../${RAW_JSONL_FILE})
python deduplicate.py ${RAW_JSONL_FILE} -o ${UNIQUE_JSONL_FILE}
echo "âœ… Crawling and deduplication complete for today."

# --- 3. ã€æ ¸å¿ƒã€‘è¿è¡Œå¢é‡è¿‡æ»¤è„šæœ¬ ---
echo "--- Step 2: Filtering for new papers only ---"
# è°ƒç”¨æ–°è„šæœ¬ï¼Œæ¯”è¾ƒä»Šå¤©çš„æ–‡ä»¶å’Œè¿‡å»ä¸¤å¤©çš„æ–‡ä»¶
# ä½¿ç”¨äº†æ­£ç¡®çš„æ•°ç»„å±•å¼€è¯­æ³• "${PREVIOUS_DAY_FILES[@]}"
python filter_new.py --today ${UNIQUE_JSONL_FILE} --previous-days "${PREVIOUS_DAY_FILES[@]}" --output ${NEW_ONLY_JSONL_FILE}

# --- 4. æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¼˜é›…é€€å‡º ---
echo "--- Step 3: Checking if there is any new content ---"
# -s æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
if [ ! -s "${NEW_ONLY_JSONL_FILE}" ]; then
    echo "â„¹ï¸  No new papers found compared to the last 2 days. Exiting workflow."
    # æ¸…ç†å½“å¤©çš„ä¸´æ—¶æ–‡ä»¶
    rm "$RAW_JSONL_FILE" "$UNIQUE_JSONL_FILE" "$NEW_ONLY_JSONL_FILE"
    exit 0
fi
echo "âœ… New papers found. Proceeding to AI enhancement."

# --- 5. ã€æ ¸å¿ƒã€‘è¿è¡Œ AI å¢å¼ºè„šæœ¬ (å¤„ç†çº¯æ–°æ–‡ä»¶) ---
echo "--- Step 4: Enhancing new papers with AI ---"
# **è¾“å…¥å¿…é¡»æ˜¯åªåŒ…å«æ–°è®ºæ–‡çš„æ–‡ä»¶**
python ai/enhance.py --data ${NEW_ONLY_JSONL_FILE}
echo "âœ… AI enhancement complete. Output is ${ENHANCED_JSONL_FILE}"

# --- 6. ã€æ ¸å¿ƒã€‘è¿è¡Œ Markdown ç”Ÿæˆè„šæœ¬ (å¤„ç†å¢å¼ºåçš„çº¯æ–°æ–‡ä»¶) ---
echo "--- Step 5: Converting JSONL to Markdown ---"
# **è¾“å…¥å¿…é¡»æ˜¯ AI å¢å¼ºåçš„â€œçº¯æ–°è®ºæ–‡â€æ–‡ä»¶**
python to_md/convert.py --data ${ENHANCED_JSONL_FILE}
echo "âœ… Markdown report generated at ${FINAL_MD_FILE}"

# --- 7. æ›´æ–°ä¸» README æ–‡ä»¶ ---
echo "--- Step 6: Updating main README.md ---"
python update_readme.py
echo "âœ… README.md updated."

echo "ğŸ‰ Workflow finished successfully!"
