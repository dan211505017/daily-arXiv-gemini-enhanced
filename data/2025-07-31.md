# 每日 ArXiv 摘要速递: 2025-07-31

### [Exploring the Interplay of Adiposity, Ethnicity, and Hormone Receptor Profiles in Breast Cancer Subtypes](https://arxiv.org/abs/2507.21348)

**一句话总结:** 本研究表明肥胖和种族是腔内B型乳腺癌的重要风险预测因素，提示需结合医疗和社会干预。

**Authors:** Izabel Valdez, Paramahansa Pramanik
**Categories:** `q-bio.QM`, `stat.AP`

[**[PDF]**](https://arxiv.org/pdf/2507.21348)

#### 中文摘要 (Abstract in Chinese)

> 本研究探讨了肥胖和种族如何共同影响腔内型乳腺癌的发生和预后，重点在于区分腔内A型和更具侵袭性的腔内B型肿瘤。研究利用大型流行病学数据，采用逻辑回归和中介分析等统计方法，检验了雌激素代谢、脂肪因子和慢性炎症等生物因素，以及医疗保健的可及性、社会经济地位和对体重的文化态度等社会决定因素。研究结果表明，肥胖和种族背景都是腔内B型乳腺癌风险的重要预测因素。这项研究强调，需要采取医疗干预与有针对性的社会干预相结合的策略，以减少乳腺癌领域的不平等。这些见解可以改善个体化的风险评估，指导有针对性的筛查项目，并支持解决边缘化群体所承受的更高癌症负担的政策。

---

### [Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors](https://arxiv.org/abs/2507.21260)

**一句话总结:** Adam-PnP框架通过自适应噪声估计和动态模态加权，利用多源实验数据指导蛋白质扩散模型，显著提高了重建准确性。

**Authors:** Amartya Banerjee, Xingyu Xu, Caroline Moosmüller, Harlin Lee
**Categories:** `cs.LG`, `cs.AI`, `q-bio.QM`

[**[PDF]**](https://arxiv.org/pdf/2507.21260)

#### 中文摘要 (Abstract in Chinese)

> 在逆问题中，目标是从测量数据中恢复未知的参数，而测量数据通常会经过有损或有噪声的转换。最近，深度生成模型，特别是扩散模型，已经成为蛋白质结构生成的强大先验。然而，如何整合来自多个来源的噪声实验数据来指导这些模型仍然是一个巨大的挑战。现有的方法通常需要精确的实验噪声水平知识，并且需要手动调整每种数据类型的权重。为了解决这个问题，我们提出了Adam-PnP，这是一个即插即用的框架，它利用来自多个异构实验来源的梯度来引导预训练的蛋白质扩散模型。我们的框架具有自适应噪声估计方案和动态模态加权机制，这些机制被集成到扩散过程中，从而减少了手动调整超参数的需求。在复杂重建任务上的实验表明，使用Adam-PnP可以显著提高准确性。

---

### [Data Leakage and Redundancy in the LIT-PCBA Benchmark](https://arxiv.org/abs/2507.21404)

**一句话总结:** LIT-PCBA基准由于数据泄露和冗余而存在根本性缺陷，导致简单的记忆模型优于复杂的模型。

**Authors:** Amber Huang, Ian Scott Knight, Slava Naprienko
**Categories:** `cs.LG`, `q-bio.QM`

[**[PDF]**](https://arxiv.org/pdf/2507.21404)

#### 中文摘要 (Abstract in Chinese)

> LIT-PCBA是一个广泛使用的虚拟筛选基准，但我们的审核显示它存在根本性的缺陷。该数据集存在严重的数据泄露、大量重复和普遍的类似物冗余问题——这些缺陷使其无法用于公平的模型评估。值得注意的是，我们发现2,491个非活性化合物在训练集和验证集中重复出现，并且在单个数据分割中重复出现了数千个（训练集中2,945个，验证集中789个）。关键的是，查询集中的三个配体——本应代表未见过的测试用例——被泄露：两个出现在训练集中，一个出现在验证集中。结构冗余加剧了这些问题：对于某些靶标，超过80%的查询配体是近似重复的，Tanimoto相似度>=0.9。仅在ALDH1中，我们发现训练集和验证集之间有323个高度相似的活性配对，这使得化学多样性的说法无效。这些和其他缺陷共同导致在LIT-PCBA上训练的模型记住而不是泛化。为了证明这些数据完整性失败的后果，我们实现了一个简单的基于记忆的基线——不使用任何学习、物理或建模——仅仅通过利用这些伪像，它在LIT-PCBA上优于最先进的模型，包括像CHEESE这样的深度神经网络。我们的发现表明该基准不适合其预期用途，并对之前基于其使用而得出的结果提出质疑。我们分享此审核以提高认识，并提供工具来帮助社区开发更严格和可靠的数据集。重现我们的审核和基线实现所需的所有脚本都可以在以下网址获得：https://github.com/sievestack/LIT-PCBA-audit
