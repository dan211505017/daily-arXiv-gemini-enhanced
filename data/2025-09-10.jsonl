{"id": "2509.05309", "pdf": "https://arxiv.org/pdf/2509.05309", "abs": "https://arxiv.org/abs/2509.05309", "authors": ["Xiangyu Liu", "Haodi Lei", "Yi Liu", "Yang Liu", "Wei Hu"], "title": "ProtSAE: Disentangling and Interpreting Protein Language Models via Semantically-Guided Sparse Autoencoders", "categories": ["q-bio.QM", "cs.AI", "cs.CL"], "comment": null, "summary": "Sparse Autoencoder (SAE) has emerged as a powerful tool for mechanistic\ninterpretability of large language models. Recent works apply SAE to protein\nlanguage models (PLMs), aiming to extract and analyze biologically meaningful\nfeatures from their latent spaces. However, SAE suffers from semantic\nentanglement, where individual neurons often mix multiple nonlinear concepts,\nmaking it difficult to reliably interpret or manipulate model behaviors. In\nthis paper, we propose a semantically-guided SAE, called ProtSAE. Unlike\nexisting SAE which requires annotation datasets to filter and interpret\nactivations, we guide semantic disentanglement during training using both\nannotation datasets and domain knowledge to mitigate the effects of entangled\nattributes. We design interpretability experiments showing that ProtSAE learns\nmore biologically relevant and interpretable hidden features compared to\nprevious methods. Performance analyses further demonstrate that ProtSAE\nmaintains high reconstruction fidelity while achieving better results in\ninterpretable probing. We also show the potential of ProtSAE in steering PLMs\nfor downstream generation tasks."}
{"id": "2509.05846", "pdf": "https://arxiv.org/pdf/2509.05846", "abs": "https://arxiv.org/abs/2509.05846", "authors": ["Hamed Karami", "Ruiyan Luo", "Pejman Sanaei", "Gerardo Chowell"], "title": "Comparative study of Bayesian and Frequentist methods for epidemic forecasting: Insights from simulated and historical data", "categories": ["q-bio.QM"], "comment": null, "summary": "Accurate epidemic forecasting is critical for effective public health\ninterventions. This study compares Bayesian and Frequentist estimation\nframeworks within deterministic compartmental epidemic models, focusing on\nnonlinear least squares optimization versus Bayesian inference using MCMC\nsampling via Stan. We compare forecasting performance under shared modeling\nstructure and error assumptions for specific implementations of both\napproaches.\n  We assess performance on simulated datasets (with R0 values of 2 and 1.5) and\nhistorical datasets including the 1918 influenza pandemic, 1896-97 Bombay\nplague, and COVID-19 pandemic. Evaluation metrics include Mean Absolute Error,\nRoot Mean Squared Error, Weighted Interval Score, and 95% prediction interval\ncoverage.\n  Forecasting performance depends on epidemic phase and dataset\ncharacteristics, with no method consistently outperforming across all contexts.\nFrequentist methods perform well at peak and post-peak phases but are less\naccurate pre-peak. Bayesian methods, particularly with uniform priors, offer\nbetter early-epidemic accuracy and stronger uncertainty quantification,\nespecially valuable when data are sparse or noisy. Frequentist methods often\nyield more accurate point forecasts with lower error metrics, though their\ninterval estimates may be less robust.\n  We examine how prior choice influences Bayesian forecasts and how extending\nforecasting horizons affects convergence. These findings offer practical\nguidance for choosing estimation strategies tailored to epidemic phase and data\nquality, supporting more effective public health interventions."}
{"id": "2509.06192", "pdf": "https://arxiv.org/pdf/2509.06192", "abs": "https://arxiv.org/abs/2509.06192", "authors": ["Ellen Visscher", "Michael Forbes", "Christopher Yau"], "title": "Hybrid restricted master problem for Boolean matrix factorisation", "categories": ["q-bio.QM"], "comment": null, "summary": "We present bfact, a Python package for performing accurate low-rank Boolean\nmatrix factorisation (BMF). bfact uses a hybrid combinatorial optimisation\napproach based on a priori candidate factors generated from clustering\nalgorithms. It selects the best disjoint factors before performing either a\nsecond combinatorial or heuristic algorithm to recover the BMF. We show that\nbfact does particularly well at estimating the true rank of matrices in\nsimulated settings. In real benchmarks, using a collation of single-cell\nRNA-sequencing datasets from the Human Lung Cell Atlas, we show that bfact\nachieves strong signal recovery, with a much lower rank."}
{"id": "2509.06735", "pdf": "https://arxiv.org/pdf/2509.06735", "abs": "https://arxiv.org/abs/2509.06735", "authors": ["Bartosz Prokop", "Lendert Gelens"], "title": "Data-driven discovery of dynamical models in biology", "categories": ["q-bio.QM"], "comment": "26 pages, 5 figures, 6 Info boxes", "summary": "Dynamical systems theory describes how interacting quantities change over\ntime and space, from molecular oscillators to large-scale biological patterns.\nSuch systems often involve nonlinear feedbacks, delays, and interactions across\nscales. Classical modeling derives explicit governing equations, often systems\nof differential equations, by combining mechanistic assumptions, experimental\nobservations, and known physical laws. The growing complexity of biological\nprocesses has, however, motivated complementary data-driven methods that aim to\ninfer model structure directly from measurements, often without specifying\nequations a priori. In this review, we survey approaches for model discovery in\nbiological dynamical systems, focusing on three methodological families:\nregression-based methods, network-based architectures, and decomposition\ntechniques. We compare their ability to address three core goals: forecasting\nfuture states, identifying interactions, and characterizing system states.\nRepresentative methods are applied to a common benchmark, the Oregonator model,\na minimal nonlinear oscillator that captures shared design principles of\nchemical and biological systems. By highlighting strengths, limitations, and\ninterpretability, we aim to guide researchers in selecting tools for analyzing\ncomplex, nonlinear, and high-dimensional dynamics in the life sciences."}
{"id": "2509.05373", "pdf": "https://arxiv.org/pdf/2509.05373", "abs": "https://arxiv.org/abs/2509.05373", "authors": ["Yuna Lim", "Yubin Seo", "Jacob Lee", "Eunok Jung"], "title": "Comparison of the effectiveness and costs of hepatitis A vaccination strategies to mitigate future deaths in the Republic of Korea", "categories": ["q-bio.PE"], "comment": null, "summary": "Improved hygiene and infant vaccinations have led to age specific variations\nin hepatitis A antibody prevalence in Korea, with lower rates among individuals\nin their 20s to 40s. Given that the fatality rate of hepatitis A increases for\nthose aged 50 and older, the low immunity level among younger adults indicates\na future risk of increased deaths in older age groups without additional\npreventive measures.We developed an age structured transmission model to assess\nthe impact of adult vaccination, assuming it begins in 2025. The 20s age group\nwas modeled with an additional compartment to account for hepatitis A\nvaccination administered to military recruits. Vaccination strategies targeting\nthe 20s to 30s and 40s to 50s age groups were compared, considering antibody\ntesting costs for the latter in Korea and focusing on projected deaths over\napproximately 50 years. When the total vaccination cost is fixed, targeting the\n40s to 50s group covers 20% fewer individuals than the 20s to 30s group but\nyields a 1.3 to 1.5 fold greater reduction in deaths. When the total vaccine\nsupply is fixed, targeting the 40s to 50s group is 1.2 times more expensive but\nyields a 1.7 to 1.8 fold greater reduction in deaths than the 20s to 30s group.\nMoreover, including a second dose for military personnel in the 20s to 30s\ngroup has minimal impact on reducing deaths. Preventive measures for adults may\nbe necessary to reduce future hepatitis A related deaths. Vaccinating the 40s\nto 50s group would be more effective in reducing deaths than vaccinating the\n20s to 30s group."}
{"id": "2509.05539", "pdf": "https://arxiv.org/pdf/2509.05539", "abs": "https://arxiv.org/abs/2509.05539", "authors": ["Charalampos Koilakos", "Kimonas Provatas", "Michail Patsakis", "Aris Karatzikos", "Ilias Georgakopoulos-Soares"], "title": "Investigating DNA words and their distributions across the tree of life", "categories": ["q-bio.GN"], "comment": null, "summary": "The frequency distributions of DNA k-mers are shaped by fundamental\nbiological processes and offer a window into genome structure and evolution.\nInspired by analogies to natural language, prior studies have attempted to\nmodel genomic k-mer usage using Zipf's law, a rank-frequency law originally\nformulated for words in human language. However, the extent to which this law\naccurately captures the distribution of k-mers across diverse species remains\nunclear. Here, we systematically analyze k-mer frequency spectra across more\nthan 225,000 genome assemblies spanning all three domains of life and viruses.\nWe demonstrate that Zipf's law consistently underperforms in modeling k-mer\ndistributions. In contrast, we propose the truncated power law and\nZipf-Mandelbrot distributions, which provide substantially improved fits across\ntaxonomic groups. We show that genome size and GC content influence model\nperformance, with larger and GC-content imbalanced genomes yielding better\nadherence. Additionally, we perform an extensive analysis on vocabulary\nexpansion and exhaustion across the same organisms using Heaps' law. We apply\nour modeling framework to evaluate simulated genomes generated by k-let\npreserving shuffling and deep generative language models. Our results reveal\nsubstantial differences between organismal genomes and their synthetic or\nshuffled counterparts, offering a novel approach to benchmark the biological\nplausibility of artificial genomes. Collectively, this work establishes new\nstandards for modeling genomic k-mer distributions and provides insights\nrelevant to synthetic biology, and evolutionary sequence analysis."}
{"id": "2509.05481", "pdf": "https://arxiv.org/pdf/2509.05481", "abs": "https://arxiv.org/abs/2509.05481", "authors": ["Eric Palanques-Tost", "Hanna Krasowski", "Murat Arcak", "Ron Weiss", "Calin Belta"], "title": "STL-based Optimization of Biomolecular Neural Networks for Regression and Control", "categories": ["cs.LG", "q-bio.MN", "q-bio.QM"], "comment": null, "summary": "Biomolecular Neural Networks (BNNs), artificial neural networks with\nbiologically synthesizable architectures, achieve universal function\napproximation capabilities beyond simple biological circuits. However, training\nBNNs remains challenging due to the lack of target data. To address this, we\npropose leveraging Signal Temporal Logic (STL) specifications to define\ntraining objectives for BNNs. We build on the quantitative semantics of STL,\nenabling gradient-based optimization of the BNN weights, and introduce a\nlearning algorithm that enables BNNs to perform regression and control tasks in\nbiological systems. Specifically, we investigate two regression problems in\nwhich we train BNNs to act as reporters of dysregulated states, and a feedback\ncontrol problem in which we train the BNN in closed-loop with a chronic disease\nmodel, learning to reduce inflammation while avoiding adverse responses to\nexternal infections. Our numerical experiments demonstrate that STL-based\nlearning can solve the investigated regression and control tasks efficiently."}
{"id": "2509.05508", "pdf": "https://arxiv.org/pdf/2509.05508", "abs": "https://arxiv.org/abs/2509.05508", "authors": ["Katherine M. Jia", "Christopher B. Boyer", "Alyssa Bilinski", "Marc Lipsitch"], "title": "Defining and Estimating Outcomes Directly Averted by a Vaccination Program when Rollout Occurs Over Time", "categories": ["q-bio.PE"], "comment": null, "summary": "During the COVID-19 pandemic, estimating the total deaths averted by\nvaccination has been of great public health interest. Instead of estimating\ntotal deaths averted by vaccination among both vaccinated and unvaccinated\nindividuals, some studies empirically estimated only \"directly averted\" deaths\namong vaccinated individuals, typically suggesting that vaccines prevented more\ndeaths overall than directly due to the indirect effect. Here, we define the\ncausal estimand to quantify outcomes \"directly averted\" by\nvaccination$\\unicode{x2014}$i.e., the impact of vaccination for vaccinated\nindividuals, holding vaccination coverage fixed$\\unicode{x2014}$for vaccination\nat multiple time points, and show that this estimand is a lower bound on the\ntotal outcomes averted when the indirect effect is non-negative. We develop an\nunbiased estimator for the causal estimand in a one-stage randomized controlled\ntrial (RCT) and explore the bias of a popular \"hazard difference\" estimator\nfrequently used in empirical studies. We show that even in an RCT, the hazard\ndifference estimator is biased if vaccination has a non-null effect, as it\nfails to incorporate the greater depletion of susceptibles among the\nunvaccinated individuals. In simulations, the overestimation is small for\naverted deaths when infection-fatality rate is low, as for many important\npathogens. However, the overestimation can be large for averted infections\ngiven a high basic reproduction number. Additionally, we define and compare\nestimand and estimators for avertible outcomes (i.e., outcomes that could have\nbeen averted by vaccination, but were not due to failure to vaccinate). Future\nstudies can explore the identifiability of the causal estimand in observational\nsettings."}
{"id": "2509.06234", "pdf": "https://arxiv.org/pdf/2509.06234", "abs": "https://arxiv.org/abs/2509.06234", "authors": ["Michail Patsakis", "Ioannis Mouratidis", "Ilias Georgakopoulos-Soares"], "title": "Minimum-Cost Synthetic Genome Planning: An Algorithmic Framework", "categories": ["q-bio.GN"], "comment": null, "summary": "As synthetic genomics scales toward the construction of increasingly larger\ngenomes, computational strategies are needed to address technical feasibility.\nWe introduce an algorithmic framework for the Minimum-Cost Synthetic Genome\nPlanning problem, aiming to identify the most cost-effective strategy to\nassemble a target genome from a source genome through a combination of reuse,\nsynthesis, and join operations. By comparing dynamic programming and greedy\nheuristic strategies under diverse cost regimes, we demonstrate how algorithmic\nchoices influence the cost-efficiency of large-scale genome construction. In\nparallel, solving the Minimum-Cost Synthetic Genome Planning problem can help\nus better understand genome architecture and evolution. We applied our\nframework in case studies on viral genomes, including SARS-CoV-2, to examine\nhow source-target genome similarity shapes construction costs. Our analyses\nrevealed that conserved regions such as ORF1ab can be reconstructed\ncost-effectively from related templates, while highly variable regions such as\nthe S (spike) gene are more reliant on DNA synthesis, highlighting the\nbiological and economic trade-offs of genome design."}
{"id": "2509.06271", "pdf": "https://arxiv.org/pdf/2509.06271", "abs": "https://arxiv.org/abs/2509.06271", "authors": ["Jayanth Venkatarama Reddy", "Nelson Ndahiro", "Lateef Aliyu", "Ashwin Dravid", "Tianxin Xang", "Jinke Wu", "Michael Betenbaugh", "Marc Donohue"], "title": "Computational predictions of nutrient precipitation for intensified cell 1 culture media via amino acid solution thermodynamics", "categories": ["q-bio.BM", "physics.bio-ph", "q-bio.QM"], "comment": "32 pages, 8 figures", "summary": "The majority of therapeutic monoclonal antibodies (mAbs) on the market are\nproduced using Chinese Hamster Ovary (CHO) cells cultured at scale in\nchemically defined cell culture medium. Because of the high costs associated\nwith mammalian cell cultures, obtaining high cell densities to produce high\nproduct titers is desired. These bioprocesses require high concentrations of\nnutrients in the basal media and periodically adding concentrated feed media to\nsustain cell growth and therapeutic protein productivity. Unfortunately, the\ndesired or optimal nutrient concentrations of the feed media are often\nsolubility limited due to precipitation of chemical complexes that form in the\nsolution. Experimentally screening the various cell culture media\nconfigurations which contain 50 to 100 compounds can be expensive and\nlaborious. This article lays the foundation for utilizing computational tools\nto understand precipitation of nutrients in cell culture media by studying the\npairwise interactions between amino acids in thermodynamic models. Activity\ncoefficient data for one amino acid in water and amino acid solubility data of\ntwo amino acids in water have been used to determine a single set of UNIFAC\ngroup interaction parameters to predict the thermodynamic behavior of the\nmulti-component systems found in mammalian cell culture media. The data\ncollected in this study is, to our knowledge, the largest set of ternary system\namino acid solubility data reported to date. These amino acid precipitation\npredictions have been verified with experimentally measured ternary and\nquaternary amino acid solutions. Thus, we demonstrate the utility of our model\nas a digital twin to identify optimal cell culture media compositions by\nreplacing empirical approaches for nutrient precipitation with computational\npredictions based on thermodynamics of individual media components in complex\nmixtures."}
{"id": "2509.05731", "pdf": "https://arxiv.org/pdf/2509.05731", "abs": "https://arxiv.org/abs/2509.05731", "authors": ["Jean-Marc Mandeng"], "title": "Modeling Cholera Dynamics Under Food Insecurity and Environmental Contamination: A Multi-Patch Approach", "categories": ["q-bio.PE", "math.DS"], "comment": null, "summary": "We propose a multi-patch model of cholera transmission integrating\nenvironmental contamination, human mobility, and nutritional vulnerability. The\npopulation is stratified by food security status, and transmission occurs via\nhuman contact, bacteria in the environment and contaminated food. We derive the\nbasic reproduction number $\\mathcal{R}_0$ analyze the stability of the\ndisease-free equilibria and show a forward bifurcation. Numerical simulations\nillustrate how food insecurity amplifies outbreak severity and mortality. The\nmodel highlights the role of spatial heterogeneity and socio-environmental\nfactors in shaping cholera dynamics. Moreover, results show the impact of sinks\ninside starting epidemic."}
{"id": "2509.06329", "pdf": "https://arxiv.org/pdf/2509.06329", "abs": "https://arxiv.org/abs/2509.06329", "authors": ["Ruiming Du", "Guangxun Zhai", "Tian Qiu", "Yu Jiang"], "title": "Towards scalable organ level 3D plant segmentation: Bridging the data algorithm computing gap", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "The precise characterization of plant morphology provides valuable insights\ninto plant environment interactions and genetic evolution. A key technology for\nextracting this information is 3D segmentation, which delineates individual\nplant organs from complex point clouds. Despite significant progress in general\n3D computer vision domains, the adoption of 3D segmentation for plant\nphenotyping remains limited by three major challenges: i) the scarcity of\nlarge-scale annotated datasets, ii) technical difficulties in adapting advanced\ndeep neural networks to plant point clouds, and iii) the lack of standardized\nbenchmarks and evaluation protocols tailored to plant science. This review\nsystematically addresses these barriers by: i) providing an overview of\nexisting 3D plant datasets in the context of general 3D segmentation domains,\nii) systematically summarizing deep learning-based methods for point cloud\nsemantic and instance segmentation, iii) introducing Plant Segmentation Studio\n(PSS), an open-source framework for reproducible benchmarking, and iv)\nconducting extensive quantitative experiments to evaluate representative\nnetworks and sim-to-real learning strategies. Our findings highlight the\nefficacy of sparse convolutional backbones and transformer-based instance\nsegmentation, while also emphasizing the complementary role of modeling-based\nand augmentation-based synthetic data generation for sim-to-real learning in\nreducing annotation demands. In general, this study bridges the gap between\nalgorithmic advances and practical deployment, providing immediate tools for\nresearchers and a roadmap for developing data-efficient and generalizable deep\nlearning solutions in 3D plant phenotyping. Data and code are available at\nhttps://github.com/perrydoremi/PlantSegStudio."}
{"id": "2509.06062", "pdf": "https://arxiv.org/pdf/2509.06062", "abs": "https://arxiv.org/abs/2509.06062", "authors": ["Chloë Mian", "Sylvain Billiard", "Violaine Llaurens", "Charline Smadi"], "title": "Dynamics of Two Species with Density-Dependent Interactions in a Mutualistic Context", "categories": ["q-bio.PE", "math.CA", "math.DS"], "comment": null, "summary": "Mutualistic interactions, where individuals from different species can\nbenefit from each other, are widespread across ecosystems. This study develops\na general deterministic model of mutualism involving two populations, assuming\nthat mutualism may involve both costs and benefits for the interacting\nindividuals, leading to density-dependent effects on the dynamics of the two\nspecies. This framework aims at generalizing pre-existing models, by allowing\nthe ecological interactions to transition from mutualistic to parasitic when\nthe respective densities of interacting species change. Through ordinary\ndifferential equations and phase portrait analysis, we derive general\nprinciples governing these systems, identifying sufficient conditions for the\nemergence of certain dynamic behaviors. In particular, we show that limit\ncycles can arise when interactions include parasitic phases but are absent in\nstrictly mutualistic regimes. This framework provides a general approach for\ncharacterizing the population dynamics of interacting species and highlights\nthe effect of the transitions from mutualism to parasitism due to density\ndependence."}
{"id": "2509.06503", "pdf": "https://arxiv.org/pdf/2509.06503", "abs": "https://arxiv.org/abs/2509.06503", "authors": ["Eser Aygün", "Anastasiya Belyaeva", "Gheorghe Comanici", "Marc Coram", "Hao Cui", "Jake Garrison", "Renee Johnston Anton Kast", "Cory Y. McLean", "Peter Norgaard", "Zahra Shamsi", "David Smalling", "James Thompson", "Subhashini Venugopalan", "Brian P. Williams", "Chujun He", "Sarah Martinson", "Martyna Plomecka", "Lai Wei", "Yuchen Zhou", "Qian-Ze Zhu", "Matthew Abraham", "Erica Brand", "Anna Bulanova", "Jeffrey A. Cardille", "Chris Co", "Scott Ellsworth", "Grace Joseph", "Malcolm Kane", "Ryan Krueger", "Johan Kartiwa", "Dan Liebling", "Jan-Matthis Lueckmann", "Paul Raccuglia", "Xuefei", "Wang", "Katherine Chou", "James Manyika", "Yossi Matias", "John C. Platt", "Lizzie Dorfman", "Shibl Mourad", "Michael P. Brenner"], "title": "An AI system to help scientists write expert-level empirical software", "categories": ["cs.AI", "q-bio.QM"], "comment": "71 pages, 26 figures", "summary": "The cycle of scientific discovery is frequently bottlenecked by the slow,\nmanual creation of software to support computational experiments. To address\nthis, we present an AI system that creates expert-level scientific software\nwhose goal is to maximize a quality metric. The system uses a Large Language\nModel (LLM) and Tree Search (TS) to systematically improve the quality metric\nand intelligently navigate the large space of possible solutions. The system\nachieves expert-level results when it explores and integrates complex research\nideas from external sources. The effectiveness of tree search is demonstrated\nacross a wide range of benchmarks. In bioinformatics, it discovered 40 novel\nmethods for single-cell data analysis that outperformed the top human-developed\nmethods on a public leaderboard. In epidemiology, it generated 14 models that\noutperformed the CDC ensemble and all other individual models for forecasting\nCOVID-19 hospitalizations. Our method also produced state-of-the-art software\nfor geospatial analysis, neural activity prediction in zebrafish, time series\nforecasting and numerical solution of integrals. By devising and implementing\nnovel solutions to diverse tasks, the system represents a significant step\ntowards accelerating scientific progress."}
{"id": "2509.05807", "pdf": "https://arxiv.org/pdf/2509.05807", "abs": "https://arxiv.org/abs/2509.05807", "authors": ["Rodrigo Fernández-Martínez", "Alfonso Ruiz-Herrera"], "title": "Mosquito population suppression models with seasonality and d-concave equations", "categories": ["math.DS", "q-bio.PE"], "comment": null, "summary": "The sterile insect technique has emerged recently as a biologically secure\nand effective tool for suppressing wild mosquito pests. To improve the\nperformance of this strategy, understanding the interaction between wild and\nsterile mosquitoes is critical. Although the common models for this biological\nproblem are scalar equations, they are remarkably resistant to the mathematical\nanalysis. In a series of papers, Due\\~nas, Nu\\~nez, and Obaya have developed a\npowerful approach to describe the dynamical behavior of scalar equations with\nd-concave nonlinearities, a property typically related to the sign of the third\nderivative. In this paper, we show that, for periodic equations coming from\npopulation dynamics, this condition is typically associated with the positive\nsign of the third derivative of the inverse of the Poincar\\'e map. This remark\nallows us to simplify some arguments in the periodic case and obtain a deep\ngeometrical understanding of the global bifurcation patterns. Consequently, the\ndynamical behavior of the models is analyzed in terms of simple and testable\nconditions. Our methodology allows us to describe precisely the dynamical\nbehavior of the common mosquito population suppression models, even\nincorporating seasonality. This paper generalizes and improves many recent\nresults in the literature."}
{"id": "2509.06849", "pdf": "https://arxiv.org/pdf/2509.06849", "abs": "https://arxiv.org/abs/2509.06849", "authors": ["Boryeu Mao"], "title": "Canonicalization of the E value from BLAST similarity search -- dissimilarity measure and distance function for a metric space of protein sequences", "categories": ["q-bio.BM", "q-bio.QM"], "comment": "34 pages, 4 figures, 3 tables", "summary": "Sequence matching algorithms such as BLAST and FASTA have been widely used in\nsearching for evolutionary origin and biological functions of newly discovered\nnucleic acid and protein sequences. As parts of these search tools, alignment\nscores and E values are useful indicators of the quality of search results from\nquerying a database of annotated sequences, whereby a high alignment score (and\ninversely a low E value) reflects significant similarity between the query and\nthe subject (target) sequences. For cross-comparison of results from\nsufficiently different queries however, the interpretation of alignment score\nas a similarity measure and E value a dissimilarity measure becomes somewhat\nnuanced, and prompts herein a judicious distinction of different types of\nsimilarity. We show that an adjustment of E value to account for self-matching\nof query and subject sequences corrects for certain ostensibly anomalous\nsimilarity comparisons, resulting in canonical dissimilarity and similarity\nmeasures that would be more appropriate for database applications, such as\nall-on-all sequence alignment or selection of diverse subsets. In actual\npractice, the canonicalization of E value dissimilarity improves clustering and\nthe diversity of subset selection. While both E value and the canonical E value\nshare positivity and symmetry, two of the four axiomatic properties of a metric\nspace, the canonical E value itself is also reflexive and meets the condition\nof triangle inequality, thus an appropriate distance function for a metric\nspace of protein sequences."}
{"id": "2509.06893", "pdf": "https://arxiv.org/pdf/2509.06893", "abs": "https://arxiv.org/abs/2509.06893", "authors": ["Noble Harasha", "Nancy Lynch"], "title": "Nanobot Algorithms for Treatment of Diffuse Cancer", "categories": ["cs.MA", "cs.RO", "q-bio.QM"], "comment": "Abridged abstract shown here; 34 pages, 9 figures", "summary": "Motile nanosized particles, or \"nanobots\", promise more effective and less\ntoxic targeted drug delivery because of their unique scale and precision. We\nconsider the case in which the cancer is \"diffuse\", dispersed such that there\nare multiple distinct cancer sites. We investigate the problem of a swarm of\nnanobots locating these sites and treating them by dropping drug payloads at\nthe sites. To improve the success of the treatment, the drug payloads must be\nallocated between sites according to their \"demands\"; this requires extra\nnanobot coordination. We present a mathematical model of the behavior of the\nnanobot agents and of their colloidal environment. This includes a movement\nmodel for agents based upon experimental findings from actual nanoparticles in\nwhich bots noisily ascend and descend chemical gradients. We present three\nalgorithms: The first algorithm, called KM, is the most representative of\nreality, with agents simply following naturally existing chemical signals that\nsurround each cancer site. The second algorithm, KMA, includes an additional\nchemical payload which amplifies the existing natural signals. The third\nalgorithm, KMAR, includes another additional chemical payload which counteracts\nthe other signals, instead inducing negative chemotaxis in agents such that\nthey are repelled from sites that are already sufficiently treated. We present\nsimulation results for all algorithms across different types of cancer\narrangements. For KM, we show that the treatment is generally successful unless\nthe natural chemical signals are weak, in which case the treatment progresses\ntoo slowly. For KMA, we demonstrate a significant improvement in treatment\nspeed but a drop in eventual success, except for concentrated cancer patterns.\nFor KMAR, our results show great performance across all types of cancer\npatterns, demonstrating robustness and adaptability."}
