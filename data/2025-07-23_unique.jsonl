{"id": "2507.14269", "pdf": "https://arxiv.org/pdf/2507.14269", "abs": "https://arxiv.org/abs/2507.14269", "authors": ["Kunyang Li", "Hongfu Lou", "Dinan Peng"], "title": "MP-GCAN: a highly accurate classifier for $\u03b1$-helical membrane proteins and $\u03b2$-barrel proteins", "categories": ["q-bio.QM"], "comment": "8pages,4figures", "summary": "Membrane protein classification is a fundamental task in structural\nbioinformatics, critical to understanding protein functions and accelerating\ndrug discovery. In this study, we propose MP-GCAN, a novel graph-based\nclassification model that leverages both spatial and sequential features of\nproteins. MP-GCAN combines GCN, GAT, and GIN layers to capture hierarchical\nstructural representations from 3D protein graphs, constructed from\nhigh-resolution PDB files with $\\alpha$-carbon coordinates and residue types.\nTo evaluate performance, we curated a high-quality dataset of 500 membrane and\n500 non-membrane proteins, and compared MP-GCAN with two baselines: a\nstructure-confidence-based SGD classifier utilizing AlphaFold's pLDDT scores,\nand DeepTMHMM, a sequence-based deep learning model. Our experiments\ndemonstrate that MP-GCAN significantly outperforms baselines, achieving an\naccuracy of 96% and strong F1-scores on both classes. The results highlight the\nimportance of integrating pretrained GNN architectures with domain-specific\nstructural data to enhance membrane protein classification."}
{"id": "2507.14639", "pdf": "https://arxiv.org/pdf/2507.14639", "abs": "https://arxiv.org/abs/2507.14639", "authors": ["Saleh Alwer", "Ronan Fleming"], "title": "KinForm: Kinetics Informed Feature Optimised Representation Models for Enzyme $k_{cat}$ and $K_{M}$ Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Kinetic parameters such as the turnover number ($k_{cat}$) and Michaelis\nconstant ($K_{\\mathrm{M}}$) are essential for modelling enzymatic activity but\nexperimental data remains limited in scale and diversity. Previous methods for\npredicting enzyme kinetics typically use mean-pooled residue embeddings from a\nsingle protein language model to represent the protein. We present KinForm, a\nmachine learning framework designed to improve predictive accuracy and\ngeneralisation for kinetic parameters by optimising protein feature\nrepresentations. KinForm combines several residue-level embeddings\n(Evolutionary Scale Modeling Cambrian, Evolutionary Scale Modeling 2, and\nProtT5-XL-UniRef50), taken from empirically selected intermediate transformer\nlayers and applies weighted pooling based on per-residue binding-site\nprobability. To counter the resulting high dimensionality, we apply\ndimensionality reduction using principal--component analysis (PCA) on\nconcatenated protein features, and rebalance the training data via a\nsimilarity-based oversampling strategy. KinForm outperforms baseline methods on\ntwo benchmark datasets. Improvements are most pronounced in low sequence\nsimilarity bins. We observe improvements from binding-site probability pooling,\nintermediate-layer selection, PCA, and oversampling of low-identity proteins.\nWe also find that removing sequence overlap between folds provides a more\nrealistic evaluation of generalisation and should be the standard over random\nsplitting when benchmarking kinetic prediction models."}
{"id": "2507.15651", "pdf": "https://arxiv.org/pdf/2507.15651", "abs": "https://arxiv.org/abs/2507.15651", "authors": ["Lorenzo Rosset", "Martin Weigt", "Francesco Zamponi"], "title": "Data augmentation enables label-specific generation of homologous protein sequences", "categories": ["q-bio.QM", "cond-mat.dis-nn"], "comment": "13 pages, 4 figures", "summary": "Accurately annotating and controlling protein function from sequence data\nremains a major challenge, particularly within homologous families where\nannotated sequences are scarce and structural variation is minimal. We present\na two-stage approach for semi-supervised functional annotation and conditional\nsequence generation in protein families using representation learning. First,\nwe demonstrate that protein language models, pretrained on large and diverse\nsequence datasets and possibly finetuned via contrastive learning, provide\nembeddings that robustly capture fine-grained functional specificities, even\nwith limited labeled data. Second, we use the inferred annotations to train a\ngenerative probabilistic model, an annotation-aware Restricted Boltzmann\nMachine, capable of producing synthetic sequences with prescribed functional\nlabels. Across several protein families, we show that this approach achieves\nhighly accurate annotation quality and supports the generation of functionally\ncoherent sequences. Our findings underscore the power of combining\nself-supervised learning with light supervision to overcome data scarcity in\nprotein function prediction and design."}
{"id": "2507.14368", "pdf": "https://arxiv.org/pdf/2507.14368", "abs": "https://arxiv.org/abs/2507.14368", "authors": ["Praneeth Namburi", "Roger Pallar\u00e8s-L\u00f3pez", "Jessica Rosendorf", "Duarte Folgado", "Brian W. Anthony"], "title": "DUSTrack: Semi-automated point tracking in ultrasound videos", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "Ultrasound technology enables safe, non-invasive imaging of dynamic tissue\nbehavior, making it a valuable tool in medicine, biomechanics, and sports\nscience. However, accurately tracking tissue motion in B-mode ultrasound\nremains challenging due to speckle noise, low edge contrast, and out-of-plane\nmovement. These challenges complicate the task of tracking anatomical landmarks\nover time, which is essential for quantifying tissue dynamics in many clinical\nand research applications. This manuscript introduces DUSTrack (Deep learning\nand optical flow-based toolkit for UltraSound Tracking), a semi-automated\nframework for tracking arbitrary points in B-mode ultrasound videos. We combine\ndeep learning with optical flow to deliver high-quality and robust tracking\nacross diverse anatomical structures and motion patterns. The toolkit includes\na graphical user interface that streamlines the generation of high-quality\ntraining data and supports iterative model refinement. It also implements a\nnovel optical-flow-based filtering technique that reduces high-frequency\nframe-to-frame noise while preserving rapid tissue motion. DUSTrack\ndemonstrates superior accuracy compared to contemporary zero-shot point\ntrackers and performs on par with specialized methods, establishing its\npotential as a general and foundational tool for clinical and biomechanical\nresearch. We demonstrate DUSTrack's versatility through three use cases:\ncardiac wall motion tracking in echocardiograms, muscle deformation analysis\nduring reaching tasks, and fascicle tracking during ankle plantarflexion. As an\nopen-source solution, DUSTrack offers a powerful, flexible framework for point\ntracking to quantify tissue motion from ultrasound videos. DUSTrack is\navailable at https://github.com/praneethnamburi/DUSTrack."}
{"id": "2507.14614", "pdf": "https://arxiv.org/pdf/2507.14614", "abs": "https://arxiv.org/abs/2507.14614", "authors": ["Jan Haji\u010d jr.", "Fabian Moss"], "title": "Knowing when to stop: insights from ecology for building catalogues, collections, and corpora", "categories": ["q-bio.PE", "cs.DL", "H.5.5"], "comment": "12th International Conference on Digital Libraries for Musicology,\n  Sogang University, Seoul, South Korea, 26 September 2025", "summary": "A major locus of musicological activity-increasingly in the digital domain-is\nthe cataloguing of sources, which requires large-scale and long-lasting\nresearch collaborations. Yet, the databases aiming at covering and representing\nmusical repertoires are never quite complete, and scholars must contend with\nthe question: how much are we still missing? This question structurally\nresembles the 'unseen species' problem in ecology, where the true number of\nspecies must be estimated from limited observations. In this case study, we\napply for the first time the common Chao1 estimator to music, specifically to\nGregorian chant. We find that, overall, upper bounds for repertoire coverage of\nthe major chant genres range between 50 and 80 %. As expected, we find that\nMass Propers are covered better than the Divine Office, though not\noverwhelmingly so. However, the accumulation curve suggests that those bounds\nare not tight: a stable ~5% of chants in sources indexed between 1993 and 2020\nwas new, so diminishing returns in terms of repertoire diversity are not yet to\nbe expected. Our study demonstrates that these questions can be addressed\nempirically to inform musicological data-gathering, showing the potential of\nunseen species models in musicology."}
{"id": "2507.15050", "pdf": "https://arxiv.org/pdf/2507.15050", "abs": "https://arxiv.org/abs/2507.15050", "authors": ["Iman Tavassoly", "Adel Mehrpooya", "Parsa Mirlohi", "Zahra Abbaspourasadollah"], "title": "Systems-Level Analysis of Multisite Protein Phosphorylation: Mathematical Induction, Geometric Series, and Entropy", "categories": ["q-bio.MN", "q-bio.QM"], "comment": null, "summary": "Multisite protein phosphorylation plays a pivotal role in regulating cellular\nsignaling and decision-making processes. In this study, we focus on the\nmathematical underpinnings and informational aspects of sequential,\ndistributive phosphorylation systems. We first provide rigorous steady-state\nsolutions derived using geometric series arguments and formal mathematical\ninduction, demonstrating that the distribution of phosphorylation states\nfollows a geometric progression determined by the kinase-to-phosphatase\nactivity ratio. We then extend the analysis with entropy-based insights,\nquantifying uncertainty in phosphorylation states and examining the mutual\ninformation between kinase activity and phosphorylation levels through a\ntruncated Poisson model. These results highlight how phosphorylation dynamics\nintroduce both structured patterns and inherent signal variability. By\ncombining exact mathematical proofs with entropy analysis, this work clarifies\nkey quantitative features of multisite phosphorylation from a systems-level\nperspective."}
{"id": "2507.14829", "pdf": "https://arxiv.org/pdf/2507.14829", "abs": "https://arxiv.org/abs/2507.14829", "authors": ["Habibur R. Howlider", "Hernan A. Moreno", "Marguerite E. Mauritz", "Stephanie N. Marquez"], "title": "Partitioning of Eddy Covariance Footprint Evapotranspiration Using Field Data, UAS Observations and GeoAI in the U.S. Chihuahuan Desert", "categories": ["q-bio.PE"], "comment": null, "summary": "This study proposes a new method for computing transpiration across an eddy\ncovariance footprint using field observations of plant sap flow,\nphytomorphology sampling, uncrewed aerial system (UAS), deep learning-based\ndigital image processing, and eddy covariance micrometeorological measurements.\nThe method is applied to the Jornada Experimental Range, New Mexico, where we\naddress three key questions: (1) What are the daily summer transpiration rates\nof Mesquite (Prosopis glandulosa) and Creosote (Larrea tridentata) individuals,\nand how do these species contribute to footprint-scale evapotranspiration? (2)\nHow can the plant-level measurements be integrated for terrain-wide\ntranspiration estimates? (3) What is the contribution of transpiration to total\nevapotranspiration within the eddy covariance footprint? Data collected from\nJune to October 2022, during the North American Monsoon season, include hourly\nevapotranspiration and precipitation rates from the Ameriflux eddy covariance\nsystem (US Jo-1 Bajada site) and sap flux rates from heat-balance sensors. We\nused plant biometric measurements and supervised classification of\nmultispectral imagery to upscale from the patch to footprint-scale estimations.\nA proportional relationship between the plant's horizontal projected area and\nthe estimated number of water flow conduits was extended to the eddy covariance\nfootprint via UAS data. Our results show that Mesquite's average daily summer\ntranspiration is 2.84 mm/d, while Creosote's is 1.78 mm/d (a ratio of 1.6:1).\nThe summer footprint integrated transpiration to evapotranspiration ratio\n(T/ET) was 0.50, decreasing to 0.44 during dry spells and increasing to 0.63\nfollowing significant precipitation. Further testing of this method is needed\nin different regions to validate its applicability. With appropriate\nadjustments, it could be relevant for other areas with similar ecological\nconditions."}
{"id": "2507.15620", "pdf": "https://arxiv.org/pdf/2507.15620", "abs": "https://arxiv.org/abs/2507.15620", "authors": ["Qipeng Wang", "Shaolun Ruan", "Rui Sheng", "Yong Wang", "Min Zhu", "Huamin Qu"], "title": "TrajLens: Visual Analysis for Constructing Cell Developmental Trajectories in Cross-Sample Exploration", "categories": ["cs.CG", "q-bio.QM"], "comment": null, "summary": "Constructing cell developmental trajectories is a critical task in\nsingle-cell RNA sequencing (scRNA-seq) analysis, enabling the inference of\npotential cellular progression paths. However, current automated methods are\nlimited to establishing cell developmental trajectories within individual\nsamples, necessitating biologists to manually link cells across samples to\nconstruct complete cross-sample evolutionary trajectories that consider\ncellular spatial dynamics. This process demands substantial human effort due to\nthe complex spatial correspondence between each pair of samples. To address\nthis challenge, we first proposed a GNN-based model to predict cross-sample\ncell developmental trajectories. We then developed TrajLens, a visual analytics\nsystem that supports biologists in exploring and refining the cell\ndevelopmental trajectories based on predicted links. Specifically, we designed\nthe visualization that integrates features on cell distribution and\ndevelopmental direction across multiple samples, providing an overview of the\nspatial evolutionary patterns of cell populations along trajectories.\nAdditionally, we included contour maps superimposed on the original cell\ndistribution data, enabling biologists to explore them intuitively. To\ndemonstrate our system's performance, we conducted quantitative evaluations of\nour model with two case studies and expert interviews to validate its\nusefulness and effectiveness."}
